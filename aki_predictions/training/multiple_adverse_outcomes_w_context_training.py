# MIT Licence
#
# Copyright (c) 2022 NHS England
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
#
# This project incorporates work covered by the following copyright and permission notice:
#
#     Copyright 2021 Google Health Research.
#
#     Licensed under the Apache License, Version 2.0 (the "License");
#     you may not use this file except in compliance with the License.
#     You may obtain a copy of the License at
#
#             http://www.apache.org/licenses/LICENSE-2.0
#
#     Unless required by applicable law or agreed to in writing, software
#     distributed under the License is distributed on an "AS IS" BASIS,
#     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#     See the License for the specific language governing permissions and
#     limitations under the License.
"""
Runs occlusion on a saved model, generated by multiple_adverse_outcomes_training.
The model checkpoint artefacts must be defined in a checkpoint directory for weights to be reloaded correctly
"""
from pathlib import Path
import logging
import time
import sys

import numpy as np

from aki_predictions.ehr_prediction_modeling import config as experiment_config
from aki_predictions.ehr_prediction_modeling import types
from aki_predictions.training.multiple_adverse_outcomes_training import run
from aki_predictions.data_processing import CAP_CENTILES


def _get_config(
    data_dir,
    checkpoint_dir="",
    root_logger=None,
    steps=None,
    checkpoint_every=None,
    eval_every=None,
    summary_every=None,
    **kwargs,
):
    if root_logger is None:
        root_logger = logging.getLogger()
    root_logger.info(data_dir)

    if steps is None:
        # Default training run length
        steps = 220000
    if checkpoint_every is None:
        checkpoint_every = 4000
    if eval_every is None:
        eval_every = 4000
    if summary_every is None:
        summary_every = 1000

    if CAP_CENTILES:
        capped_string = ""
    else:
        capped_string = "_uncapped"

    data_locs_dict = {
        "records_dirpath": data_dir,
        "train_filename": f"ingest_records_output_lines_train{capped_string}.jsonl",
        "valid_filename": f"ingest_records_output_lines_validate{capped_string}.jsonl",
        "test_filename": f"ingest_records_output_lines_test{capped_string}.jsonl",
        "calib_filename": f"ingest_records_output_lines_calib{capped_string}.jsonl",
        "category_mapping": "category_mapping.json",
        "feature_mapping": "feature_mapping.json",
        "numerical_feature_mapping": "numerical_feature_mapping.json",
        "metadata_mapping": "metadata_mapping.json",
        "missing_metadata_mapping": "missing_metadata_mapping.json",
        "sequence_giveaways": "sequence_giveaways.json",
    }
    context_nact_dict = {"diagnosis": 2, "ethnic_origin": 1, "method_of_admission": 1, "sex": 1, "year_of_birth": 1}
    nact_dict = {
        types.FeatureTypes.PRESENCE_SEQ: 10,
        types.FeatureTypes.NUMERIC_SEQ: 3,
        types.FeatureTypes.CATEGORY_COUNTS_SEQ: 3,
        **context_nact_dict,
    }
    context_features = list(context_nact_dict.keys())
    var_len_context_features = ["diagnosis"]
    fixed_len_context_features = [
        cont_feat for cont_feat in context_features if cont_feat not in var_len_context_features
    ]
    identity_lookup_features = [
        types.FeatureTypes.CATEGORY_COUNTS_SEQ,
        types.FeatureTypes.ETHNIC_ORIGIN,
        types.FeatureTypes.METHOD_OF_ADMISSION,
        types.FeatureTypes.SEX,
    ]
    shared_config_kwargs = {
        "tasks": (types.TaskNames.ITU_OUTCOME, types.TaskNames.DIALYSIS_OUTCOME, types.TaskNames.MORTALITY_OUTCOME),
        "context_features": context_features,
        "fixed_len_context_features": fixed_len_context_features,
        "var_len_context_features": var_len_context_features,
        "identity_lookup_features": identity_lookup_features,
    }
    config = experiment_config.get_config(
        nact_dict=nact_dict,
        data_locs_dict=data_locs_dict,
        num_steps=steps,  # 2 for testing
        eval_num_batches=None,  # to allow exiting via out of range error
        checkpoint_every_steps=checkpoint_every,  # 1000 for full dataset, 1 for testing
        summary_every_steps=summary_every,  # 1000 for full dataset, 1 for testing
        eval_every_steps=eval_every,  # 1000 for full dataset, 1 for testing
        shared_config_kwargs=shared_config_kwargs,
        shuffle=True,
        run_occlusion_analysis=False,
        checkpoint_dir=checkpoint_dir,
        threshold_range=np.concatenate((np.arange(0.001, 0.01, 0.001), np.arange(0.01, 1, 0.01)), axis=0),
        expect_giveaways=True,
        **kwargs,
    )
    return config


def main(output_dir, data_dir, steps, checkpoint_every, eval_every, summary_every):
    """Run experiment."""
    root_logger = logging.getLogger(__name__)

    config = _get_config(
        data_dir=data_dir,
        checkpoint_dir=output_dir,
        root_logger=root_logger,
        steps=steps,
        checkpoint_every=checkpoint_every,
        eval_every=eval_every,
        summary_every=summary_every,
    )
    run(config, root_logger=root_logger)


if __name__ == "__main__":
    output_dir = sys.argv[1]
    data_dir = sys.argv[2]
    steps = int(sys.argv[3])
    checkpoint_every = int(sys.argv[4])
    eval_every = int(sys.argv[5])
    summary_every = int(sys.argv[6])

    if data_dir is None:
        data_dir = str(Path(__file__).resolve().parents[2] / "data" / "data_ingest_index_full_2022-07-11-100305")

    timestamp = time.strftime("%Y-%m-%d-%H%M%S")
    artifacts_dir = Path(output_dir)
    if artifacts_dir.is_dir() is False:
        artifacts_dir.mkdir(parents=True, exist_ok=True)
    # Configure logging
    log_formatter = logging.Formatter("%(asctime)s [%(name)s] [%(levelname)-5.5s]  %(message)s")
    root_logger = logging.getLogger()

    file_handler = logging.FileHandler("{0}/{1}.log".format(artifacts_dir, f"{timestamp}_training_w_context_log.txt"))
    file_handler.setFormatter(log_formatter)
    root_logger.addHandler(file_handler)

    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(log_formatter)
    root_logger.addHandler(console_handler)
    root_logger.setLevel(logging.DEBUG)

    main(artifacts_dir, data_dir, steps, checkpoint_every, eval_every, summary_every)
